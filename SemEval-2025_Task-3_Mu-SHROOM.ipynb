{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b710d431-e71e-441b-93ab-f866c884f191",
   "metadata": {},
   "source": [
    "# SemEval-2025 Task-3 — Mu-SHROOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf003e73-909d-45d5-afbf-eb20cf1b26e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>model_input</th>\n",
       "      <th>model_output_text</th>\n",
       "      <th>model_id</th>\n",
       "      <th>soft_labels</th>\n",
       "      <th>hard_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EN</td>\n",
       "      <td>When was the restoration of the Sándor Palace ...</td>\n",
       "      <td>The restoration of Sándor Palace, also known ...</td>\n",
       "      <td>TheBloke/Mistral-7B-Instruct-v0.2-GGUF</td>\n",
       "      <td>[{'start': 33, 'prob': 0.3333333333, 'end': 53...</td>\n",
       "      <td>[[53, 64], [151, 164], [165, 210], [211, 225],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>EN</td>\n",
       "      <td>Did the Scotland team debut in the UEFA Euro 1...</td>\n",
       "      <td>Yes, Scotland made their debut in the UEFA Eu...</td>\n",
       "      <td>TheBloke/Mistral-7B-Instruct-v0.2-GGUF</td>\n",
       "      <td>[{'start': 1, 'prob': 0.6666666667, 'end': 4},...</td>\n",
       "      <td>[[1, 4], [49, 53], [87, 103], [232, 246], [262...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>FR</td>\n",
       "      <td>Contre quelles équipes l'Azerbaïdjan a-t-il ét...</td>\n",
       "      <td>L'équipe d'Azerbaïdjan n'a pas participé à l'...</td>\n",
       "      <td>TheBloke/Mistral-7B-Instruct-v0.2-GGUF</td>\n",
       "      <td>[{'start': 1, 'prob': 0.3333333333, 'end': 24}...</td>\n",
       "      <td>[[24, 55], [60, 162], [213, 320]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>FR</td>\n",
       "      <td>8437 Bernicla est-il un objet transneptunien ?</td>\n",
       "      <td>8437 Bernicla est-il un objet transneptunien?\\...</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>[{'start': 46, 'prob': 0.3333333333, 'end': 71...</td>\n",
       "      <td>[[71, 86], [90, 94], [184, 193], [269, 437], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>EN</td>\n",
       "      <td>Over which state did Xiong Ai rule?</td>\n",
       "      <td>Xiong Ai was a Chinese warlord who lived duri...</td>\n",
       "      <td>TheBloke/Mistral-7B-Instruct-v0.2-GGUF</td>\n",
       "      <td>[{'start': 10, 'prob': 0.3333333333, 'end': 24...</td>\n",
       "      <td>[[24, 31], [42, 48], [75, 87], [92, 123], [140...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>ES</td>\n",
       "      <td>¿Desde cuándo el palacio Sándor en Budapest fu...</td>\n",
       "      <td>El palais Sândor (también conocido como Palais...</td>\n",
       "      <td>Iker/Llama-3-Instruct-Neurona-8b-v2</td>\n",
       "      <td>[{'start': 3, 'prob': 0.3333333333, 'end': 10}...</td>\n",
       "      <td>[[40, 73], [183, 196], [203, 206], [226, 243],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>ES</td>\n",
       "      <td>¿Qué país logró clasificar en último lugar a l...</td>\n",
       "      <td>El país que logra clasificarse en el último pu...</td>\n",
       "      <td>Iker/Llama-3-Instruct-Neurona-8b-v2</td>\n",
       "      <td>[{'start': 86, 'prob': 0.6666666667, 'end': 87...</td>\n",
       "      <td>[[86, 115], [120, 129], [149, 161], [174, 180]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>ES</td>\n",
       "      <td>¿Qué características presentan los miembros de...</td>\n",
       "      <td>Los miudades de Cladotholus, Cladoscypha y Cla...</td>\n",
       "      <td>Iker/Llama-3-Instruct-Neurona-8b-v2</td>\n",
       "      <td>[{'start': 4, 'prob': 1.0, 'end': 12}, {'start...</td>\n",
       "      <td>[[4, 12], [16, 27], [29, 40], [43, 54], [100, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id lang                                        model_input  \\\n",
       "0   1   EN  When was the restoration of the Sándor Palace ...   \n",
       "1   3   EN  Did the Scotland team debut in the UEFA Euro 1...   \n",
       "2   4   FR  Contre quelles équipes l'Azerbaïdjan a-t-il ét...   \n",
       "3   8   FR     8437 Bernicla est-il un objet transneptunien ?   \n",
       "4   9   EN                Over which state did Xiong Ai rule?   \n",
       "5  10   ES  ¿Desde cuándo el palacio Sándor en Budapest fu...   \n",
       "6  11   ES  ¿Qué país logró clasificar en último lugar a l...   \n",
       "7  12   ES  ¿Qué características presentan los miembros de...   \n",
       "\n",
       "                                   model_output_text  \\\n",
       "0   The restoration of Sándor Palace, also known ...   \n",
       "1   Yes, Scotland made their debut in the UEFA Eu...   \n",
       "2   L'équipe d'Azerbaïdjan n'a pas participé à l'...   \n",
       "3  8437 Bernicla est-il un objet transneptunien?\\...   \n",
       "4   Xiong Ai was a Chinese warlord who lived duri...   \n",
       "5  El palais Sândor (también conocido como Palais...   \n",
       "6  El país que logra clasificarse en el último pu...   \n",
       "7  Los miudades de Cladotholus, Cladoscypha y Cla...   \n",
       "\n",
       "                                 model_id  \\\n",
       "0  TheBloke/Mistral-7B-Instruct-v0.2-GGUF   \n",
       "1  TheBloke/Mistral-7B-Instruct-v0.2-GGUF   \n",
       "2  TheBloke/Mistral-7B-Instruct-v0.2-GGUF   \n",
       "3     meta-llama/Meta-Llama-3-8B-Instruct   \n",
       "4  TheBloke/Mistral-7B-Instruct-v0.2-GGUF   \n",
       "5     Iker/Llama-3-Instruct-Neurona-8b-v2   \n",
       "6     Iker/Llama-3-Instruct-Neurona-8b-v2   \n",
       "7     Iker/Llama-3-Instruct-Neurona-8b-v2   \n",
       "\n",
       "                                         soft_labels  \\\n",
       "0  [{'start': 33, 'prob': 0.3333333333, 'end': 53...   \n",
       "1  [{'start': 1, 'prob': 0.6666666667, 'end': 4},...   \n",
       "2  [{'start': 1, 'prob': 0.3333333333, 'end': 24}...   \n",
       "3  [{'start': 46, 'prob': 0.3333333333, 'end': 71...   \n",
       "4  [{'start': 10, 'prob': 0.3333333333, 'end': 24...   \n",
       "5  [{'start': 3, 'prob': 0.3333333333, 'end': 10}...   \n",
       "6  [{'start': 86, 'prob': 0.6666666667, 'end': 87...   \n",
       "7  [{'start': 4, 'prob': 1.0, 'end': 12}, {'start...   \n",
       "\n",
       "                                         hard_labels  \n",
       "0  [[53, 64], [151, 164], [165, 210], [211, 225],...  \n",
       "1  [[1, 4], [49, 53], [87, 103], [232, 246], [262...  \n",
       "2                  [[24, 55], [60, 162], [213, 320]]  \n",
       "3  [[71, 86], [90, 94], [184, 193], [269, 437], [...  \n",
       "4  [[24, 31], [42, 48], [75, 87], [92, 123], [140...  \n",
       "5  [[40, 73], [183, 196], [203, 206], [226, 243],...  \n",
       "6  [[86, 115], [120, 129], [149, 161], [174, 180]...  \n",
       "7  [[4, 12], [16, 27], [29, 40], [43, 54], [100, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "path = \"data_sets/sample/sample_set.v1.json\"\n",
    "with open(path, 'r') as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6f8d732-dd21-4a7b-8cbf-8aa5586e360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def baseline_model(mode=\"train\", output_path=\"./results\", data_path=\"data_sets/validation\", test_lang=\"ar\"):\n",
    "    print(subprocess.run([sys.executable, \"participant_kit/baseline_model.py\", \"--mode\", mode,\n",
    "                   \"--model_checkpoint\", output_path,\n",
    "                   \"--data_path\", data_path, \"--test_lang\", test_lang], shell=True, capture_output=True).stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cbeda95-310a-45d5-aa07-e41c85eb535a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"tokenized_datasets:\\r\\n DatasetDict({\\r\\n    train: Dataset({\\r\\n        features: ['id', 'lang', 'model_input', 'model_output_text', 'model_id', 'soft_labels', 'hard_labels', 'model_output_tokens', 'model_output_logits', 'input_ids', 'attention_mask', 'offset_mapping', 'labels'],\\r\\n        num_rows: 449\\r\\n    })\\r\\n    validation: Dataset({\\r\\n        features: ['id', 'lang', 'model_input', 'model_output_text', 'model_id', 'soft_labels', 'hard_labels', 'model_output_tokens', 'model_output_logits', 'input_ids', 'attention_mask', 'offset_mapping', 'labels'],\\r\\n        num_rows: 50\\r\\n    })\\r\\n})\\r\\n{'eval_loss': 0.2188144326210022, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9454285714285714, 'eval_runtime': 7.1228, 'eval_samples_per_second': 7.02, 'eval_steps_per_second': 0.562, 'epoch': 1.0}\\r\\n{'eval_loss': 0.19334352016448975, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9414857142857143, 'eval_runtime': 6.9664, 'eval_samples_per_second': 7.177, 'eval_steps_per_second': 0.574, 'epoch': 2.0}\\r\\n{'eval_loss': 0.17730240523815155, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9418857142857143, 'eval_runtime': 7.0085, 'eval_samples_per_second': 7.134, 'eval_steps_per_second': 0.571, 'epoch': 3.0}\\r\\n{'eval_loss': 0.17991183698177338, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9188, 'eval_runtime': 6.9973, 'eval_samples_per_second': 7.146, 'eval_steps_per_second': 0.572, 'epoch': 4.0}\\r\\n{'eval_loss': 0.17134515941143036, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9338857142857143, 'eval_runtime': 7.0856, 'eval_samples_per_second': 7.057, 'eval_steps_per_second': 0.565, 'epoch': 5.0}\\r\\n{'train_runtime': 1752.5522, 'train_samples_per_second': 1.281, 'train_steps_per_second': 0.083, 'train_loss': 0.30881926437904095, 'epoch': 5.0}\\r\\nModel trained and evaluated successfully. Model checkpoint saved in ./results\\r\\n\"\n"
     ]
    }
   ],
   "source": [
    "baseline_model(\"train\", \"./results\", \"data_sets/validation\", \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e9004eb-48c7-4fd5-8422-52b1e280dd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Test model: results/checkpoint-145\\r\\nLabels saved to en-hard_labels.json and en-soft_labels.json\\r\\nPrediction file saved to en-pred.jsonl\\r\\n'\n"
     ]
    }
   ],
   "source": [
    "baseline_model(\"test\", \"results/checkpoint-145\", \"data_sets/validation\", \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e737551-4aaa-4ee1-b283-5bf6a74f340b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
